{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# DATASET           (trainsize, testsize, ts_length)\n",
    "# SwedishLeaf :     (500, 625, 128)\n",
    "# ECG200 :          (100, 100, 96)\n",
    "# Plane :           (105, 105, 144)\n",
    "# ECG5000 :         (500, 4500, 140)\n",
    "# Epilepsy2 :       (80, 11420, 178)\n",
    "\n",
    "root = \"../weights\"\n",
    "\n",
    "for f in os.listdir(root):\n",
    "\n",
    "    try:\n",
    "        w = pd.read_csv(os.path.join(root, f)).to_numpy()\n",
    "        print(w.shape)\n",
    "        dataset = f.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        if dataset == \"SwedishLeaf\":\n",
    "            assert w.shape[1] == 128, \"f with wrong shape {}\".format(f)\n",
    "\n",
    "        elif dataset == \"ECG200\":\n",
    "            assert w.shape[1] == 96, \"f with wrong shape {}\".format(f)\n",
    "\n",
    "        elif dataset == \"Plane\":\n",
    "            assert w.shape[1] == 144, \"f with wrong shape {}\".format(f)\n",
    "\n",
    "\n",
    "        elif dataset == \"ECG5000\":\n",
    "            assert w.shape[1] == 140, \"f with wrong shape {}\".format(f)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"could not read from {}\".format(os.path.join(root, f)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"../data/ECG200.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)\n",
    "print(data[1].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "w = pd.read_csv(\"../weights/mrseql_kernelshap_ECG200.csv\")\n",
    "\n",
    "cols = []\n",
    "for col in w.columns:\n",
    "    \n",
    "    val = col.split(\".\")\n",
    "    val = val[0] + \".\" + val[1]\n",
    "    cols.val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# DATASET           (trainsize, testsize, ts_length)\n",
    "# SwedishLeaf :     (500, 625, 128)\n",
    "# ECG200 :          (100, 100, 96)\n",
    "# Plane :           (105, 105, 144)\n",
    "\n",
    "for wpath in os.listdir(\"../weights\"):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(\"../weights/{}\".format(wpath), 'r') as f:\n",
    "        \n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        for row in reader:\n",
    "            data.append([float(x) for x in row])\n",
    "\n",
    "    data = np.array(data)\n",
    "    dataset = wpath.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    if dataset == \"SwedishLeaf\":\n",
    "        assert data.shape == (625, 128), \"f with wrong shape {}\".format(wpath)\n",
    "\n",
    "    elif dataset == \"ECG200\":\n",
    "        assert data.shape == (100, 96), \"f with wrong shape {}\".format(wpath)\n",
    "\n",
    "    elif dataset == \"Plane\":\n",
    "        assert data.shape == (105, 144), \"f with wrong shape {}\".format(wpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ../models2/rocket_Plane_1\n",
      "loaded model : RocketClassifier\n",
      "RocketClassifier - Plane - accuracy: 1.0\n",
      "loading model from ../models2/resnet_Plane_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 09:05:30.964968: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-18 09:05:30.965615: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 09:05:30.967233: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 09:05:30.971155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 09:05:30.979280: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 09:05:30.979293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 09:05:30.986252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 09:05:31.482705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-18 09:05:31.942180: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 09:05:31.942411: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model : ResNetClassifier\n",
      "ResNetClassifier - Plane - accuracy: 0.9714285714285714\n",
      "loading model from ../models2/resnet_ECG200_1\n",
      "loaded model : ResNetClassifier\n",
      "ResNetClassifier - ECG200 - accuracy: 0.85\n",
      "loading model from ../models2/rocket_ECG200_1\n",
      "loaded model : RocketClassifier\n",
      "RocketClassifier - ECG200 - accuracy: 0.92\n",
      "loading model from ../models2/mrseql_ECG200_1\n",
      "loaded model : MrSEQLClassifier\n",
      "MrSEQLClassifier - ECG200 - accuracy: 0.86\n",
      "loading model from ../models2/mrseql_Plane_1\n",
      "loaded model : MrSEQLClassifier\n",
      "MrSEQLClassifier - Plane - accuracy: 1.0\n",
      "loading model from ../models2/resnet_SwedishLeaf_1\n",
      "loaded model : ResNetClassifier\n",
      "ResNetClassifier - SwedishLeaf - accuracy: 0.8544\n",
      "loading model from ../models2/rocket_SwedishLeaf_1\n",
      "loaded model : RocketClassifier\n",
      "RocketClassifier - SwedishLeaf - accuracy: 0.9664\n",
      "loading model from ../models2/mrseql_SwedishLeaf_1\n",
      "loaded model : MrSEQLClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MrSEQLClassifier - SwedishLeaf - accuracy: 0.9424\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from saliencyserieslab.classifier import SktimeClassifier\n",
    "\n",
    "for modelpath in os.listdir(\"../models2\"):\n",
    "    model = SktimeClassifier()\n",
    "    model.load_pretrained_model(os.path.join(\"../models2\", modelpath))\n",
    "    dataset = modelpath.split(\"_\")[1]\n",
    "\n",
    "    with open(\"../data/{}.pkl\".format(dataset), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(\"{} - {} - accuracy: {}\".format(model.name, dataset, model.evaluate(data[2], data[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from saliencyserieslab.classifier import SktimeClassifier\n",
    "\n",
    "modelname = \"rocket\"\n",
    "dataset = \"Plane\"\n",
    "modelpath = \"../models/{}_{}_1\".format(modelname, dataset)\n",
    "\n",
    "with open(\"../data/{}.pkl\".format(dataset), 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "model = SktimeClassifier()\n",
    "model._load_rocket()\n",
    "\n",
    "model.fit(data[0], data[1])\n",
    "\n",
    "print(model.evaluate(data[2], data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data[2], data[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
